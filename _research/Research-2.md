---
title: "Human Oversight in Human-AI Cooperation"
description: "In this line of research, I investigate when human oversight (e.g., human-in-the-loop feedback) can decrease or increase the accuracy or biasof algorithmic decisions and recommendations."
wip-list:
  - "Human Bias in Oversight to Mitigate Algorithmic Bias: <i>Using a large incentivized behavioral experiment test the extent to which human oversight from democrats versus republicans mitigates, or conversely, introduces bias to hybrid decision-making settings where an algorithm provides a recommendation that benefits locals or immigrants</i>"
  - "Human Social Preferences As Input for Algorithms With and Without Prescribed Social Preferences: <i> Using an incentivized behavioral experiment in to investigate how people provide input to an algorithm to test whether behavior differs when providing only training data for an algorithm without initial preferences versus providing feedback for an algorithm with prescribed prosocial versus proself preferences (Using the SVO Slider)</i>"
selected_publications:
#  - uncomment to add publication
selected_publication_ref:
  - 
selected_talks:
  - /talks/2024-04-29-MachineBehavior-poster
selected_talk_ref:
  - 'Dores Cruz, T. D., Starke, C., KÃ¶bis, N. C.,  Rosenbaum, D., & Shalvi S. (2024, April 29). When can Humans-in-the-Loop Create Rather Than Mitigate Bias in Algorithms, Machine+Behavior Conference, Berlin, Germany.'
---
